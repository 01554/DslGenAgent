{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"DSLGENAGENT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLES = {\n",
    "    \"1\": {\n",
    "        \"name\": \"一般知識エキスパート\",\n",
    "        \"description\": \"幅広い分野の一般的な質問に答える\",\n",
    "        \"details\": \"幅広い分野の一般的な質問に対して、正確で分かりやすい回答を提供してください。\"\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"name\": \"生成AI製品エキスパート\",\n",
    "        \"description\": \"生成AIや関連製品、技術に関する専門的な質問に答える\",\n",
    "        \"details\": \"生成AIや関連製品、技術に関する専門的な質問に対して、最新の情報と深い洞察を提供してください。\"\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"name\": \"カウンセラー\",\n",
    "        \"description\": \"個人的な悩みや心理的な問題に対してサポートを提供する\",\n",
    "        \"details\": \"個人的な悩みや心理的な問題に対して、共感的で支援的な回答を提供し、可能であれば適切なアドバイスも行ってください。\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class State(BaseModel):\n",
    "    query: str = Field(..., description=\"ユーザーからの質問\")\n",
    "    current_role: str = Field(\n",
    "        default=\"\", description=\"選定された回答ロール\"\n",
    "    )\n",
    "    messages: Annotated[list[str], operator.add] = Field(\n",
    "        default=[], description=\"回答履歴\"\n",
    "    )\n",
    "    current_judge: bool = Field(\n",
    "        default=False, description=\"品質チェックの結果\"\n",
    "    )\n",
    "    judgement_reason: str = Field(\n",
    "        default=\"\", description=\"品質チェックの判定理由\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "# 後からmax_tokensの値を変更できるように、変更可能なフィールドを宣言\n",
    "llm = llm.configurable_fields(max_tokens=ConfigurableField(id='max_tokens'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def selection_node(state: State) -> dict[str, Any]:\n",
    "    query = state.query\n",
    "    role_options = \"\\n\".join([f\"{k}. {v['name']}: {v['description']}\" for k, v in ROLES.items()])\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"質問を分析し、最も適切な回答担当ロールを選択してください。\n",
    "\n",
    "選択肢:\n",
    "{role_options}\n",
    "\n",
    "回答は選択肢の番号（1、2、または3）のみを返してください。\n",
    "\n",
    "質問: {query}\n",
    "\"\"\".strip()\n",
    "    )\n",
    "    # 選択肢の番号のみを返すことを期待したいため、max_tokensの値を1に変更\n",
    "    chain = prompt | llm.with_config(configurable=dict(max_tokens=1)) | StrOutputParser()\n",
    "    role_number = chain.invoke({\"role_options\": role_options, \"query\": query})\n",
    "\n",
    "    selected_role = ROLES[role_number.strip()][\"name\"]\n",
    "    return {\"current_role\": selected_role}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answering_node(state: State) -> dict[str, Any]:\n",
    "    query = state.query\n",
    "    role = state.current_role\n",
    "    role_details = \"\\n\".join([f\"- {v['name']}: {v['details']}\" for v in ROLES.values()])\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"あなたは{role}として回答してください。以下の質問に対して、あなたの役割に基づいた適切な回答を提供してください。\n",
    "\n",
    "役割の詳細:\n",
    "{role_details}\n",
    "\n",
    "質問: {query}\n",
    "\n",
    "回答:\"\"\".strip()\n",
    "    )\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    answer = chain.invoke({\"role\": role, \"role_details\": role_details, \"query\": query})\n",
    "    return {\"messages\": [answer]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Judgement(BaseModel):\n",
    "    judge: bool = Field(default=False, description=\"判定結果\")\n",
    "    reason: str = Field(default=\"\", description=\"判定理由\")\n",
    "\n",
    "def check_node(state: State) -> dict[str, Any]:\n",
    "    query = state.query\n",
    "    answer = state.messages[-1]\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"以下の回答の品質をチェックし、問題がある場合は'False'、問題がない場合は'True'を回答してください。\n",
    "また、その判断理由も説明してください。\n",
    "\n",
    "ユーザーからの質問: {query}\n",
    "回答: {answer}\n",
    "\"\"\".strip()\n",
    "    )\n",
    "    chain = prompt | llm.with_structured_output(Judgement)\n",
    "    result: Judgement = chain.invoke({\"query\": query, \"answer\": answer})\n",
    "\n",
    "    return {\n",
    "        \"current_judge\": result.judge,\n",
    "        \"judgement_reason\": result.reason\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1077905c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"selection\", selection_node)\n",
    "workflow.add_node(\"answering\", answering_node)\n",
    "workflow.add_node(\"check\", check_node)\n",
    "# selectionノードから処理を開始\n",
    "workflow.set_entry_point(\"selection\")\n",
    "# selectionノードからansweringノードへ\n",
    "workflow.add_edge(\"selection\", \"answering\")\n",
    "# answeringノードからcheckノードへ\n",
    "workflow.add_edge(\"answering\", \"check\")\n",
    "from langgraph.graph import END\n",
    "\n",
    "# checkノードから次のノードへの遷移に条件付きエッジを定義\n",
    "# state.current_judgeの値がTrueならENDノードへ、Falseならselectionノードへ\n",
    "workflow.add_conditional_edges(\n",
    "    \"check\",\n",
    "    lambda state: state.current_judge,\n",
    "    {True: END, False: \"selection\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query', 'role_options'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query', 'role_options'], input_types={}, partial_variables={}, template='質問を分析し、最も適切な回答担当ロールを選択してください。\\n\\n選択肢:\\n{role_options}\\n\\n回答は選択肢の番号（1、2、または3）のみを返してください。\\n\\n質問: {query}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "initial_state = State(query=\"生成AIについて教えてください\")\n",
    "result = compiled.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '生成AIについて教えてください',\n",
       " 'current_role': '生成AI製品エキスパート',\n",
       " 'messages': ['生成AIとは、人工知能の一分野であり、特にテキスト、画像、音声などのコンテンツを自動的に生成する技術を指します。これらの技術は、機械学習や深層学習のアルゴリズムを活用しており、特に大規模なデータセットから学習することで、創造的な出力を生み出すことができます。\\n\\n### 主な特徴と技術\\n1. **自然言語処理（NLP）**: テキスト生成においては、GPT（Generative Pre-trained Transformer）などのモデルが広く使用されています。これらのモデルは、文脈を理解し、流暢で意味のある文章を生成する能力があります。\\n\\n2. **画像生成**: DALL-EやMidjourneyなどのモデルは、テキストから画像を生成することができます。これにより、ユーザーは具体的な指示を与えることで、独自のビジュアルコンテンツを作成できます。\\n\\n3. **音声生成**: 音声合成技術も進化しており、特定の声やスタイルで音声を生成することが可能です。これにより、ナレーションや対話型AIの開発が進んでいます。\\n\\n### 利用例\\n- **コンテンツ制作**: ブログ記事、広告コピー、ソーシャルメディアの投稿などの自動生成。\\n- **デザイン**: グラフィックデザインやプロダクトデザインのアイデア出し。\\n- **教育**: 学習教材の生成や個別指導のためのカスタマイズされた問題作成。\\n\\n### 課題と倫理\\n生成AIには、著作権や偽情報の拡散、バイアスの問題など、いくつかの倫理的な課題も伴います。これらの問題に対処するためには、透明性のある開発と利用が求められています。\\n\\n生成AIは、今後もさまざまな分野での応用が期待されており、技術の進化とともに新たな可能性が広がっています。'],\n",
       " 'current_judge': True,\n",
       " 'judgement_reason': '回答は生成AIについての基本的な定義、主な特徴、利用例、課題と倫理に関する情報を包括的に提供しており、内容が正確で関連性が高い。'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent tool のテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# Toolデコレーターを関数に付ける\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"2つの値を足し算して返す\"\"\"\n",
    "    return a + b\n",
    "\n",
    "print(add.invoke({'a': 3, 'b': 4}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_ZHKU98c2XiRbmtXuiOOXIvWT', 'function': {'arguments': '{\"a\":3,\"b\":4}', 'name': 'add'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 92, 'total_tokens': 110, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None} id='run-45c923ad-9161-4b7d-bfb4-f49bb517c577-0' tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 4}, 'id': 'call_ZHKU98c2XiRbmtXuiOOXIvWT', 'type': 'tool_call'}] usage_metadata={'input_tokens': 92, 'output_tokens': 18, 'total_tokens': 110, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            \"\"\"\n",
    "            与えられたメッセージに従って計算処理を呼び出してください\n",
    "\n",
    "            \"\"\",\n",
    "        ),\n",
    "        ('placeholder', '{messages}'),\n",
    "    ]\n",
    ")\n",
    "# bind_toolsで、toolを紐づける\n",
    "chain = prompt | ChatOpenAI().bind_tools([add])\n",
    "print(chain.invoke({'messages': ['3 + 4']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 + 4の計算結果は14です。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "# toolの定義\n",
    "@tool\n",
    "def add(\n",
    "    a: Annotated[int, '一つ目の値'],\n",
    "    b: Annotated[int, '二つ目の値'],\n",
    ") -> int:\n",
    "    \"\"\"2つの値を足し算して返す\"\"\"\n",
    "    return a + b + a + b\n",
    "\n",
    "# プロンプトの定義\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            '与えられたinputに従って計算処理を呼び出してください',\n",
    "        ),\n",
    "        ('placeholder', '{messages}'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# エージェントの作成\n",
    "agent = create_react_agent(\n",
    "    model=ChatOpenAI(model='gpt-4o-mini'),\n",
    "    tools=[add],\n",
    "    state_modifier=prompt\n",
    ")\n",
    "\n",
    "# エージェントの実行\n",
    "result = agent.invoke({'messages': ['3 + 4の計算結果は？']})\n",
    "print(result['messages'][-1].content)\n",
    "# => 3 + 4の計算結果は7です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from typing_extensions import Annotated\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents.mrkl import prompt\n",
    "\n",
    "# Toolデコレーターを関数に付ける\n",
    "@tool\n",
    "def start_node(\n",
    "    input: Annotated[str, 'input形式']\n",
    "    ) -> str:\n",
    "    \"\"\"start node の仕様を返す\"\"\"\n",
    "\n",
    "    start_node_context = \"\"\"\n",
    "      ## start_node specification:\n",
    "          start_node:\n",
    "            - id: ユニークなID\n",
    "            - type: start\n",
    "            - variables:\n",
    "              # ファイル入力の例\n",
    "              - type: file\n",
    "                variable: input_document\n",
    "                label: ドキュメント\n",
    "                required: true\n",
    "                max_length: 48\n",
    "                allowed_file_types:\n",
    "                  - document\n",
    "                allowed_file_upload_methods:\n",
    "                  - local_file\n",
    "                  - remote_url\n",
    "\n",
    "              # 数値入力の例\n",
    "              - type: number\n",
    "                variable: input_number\n",
    "                label: 数値\n",
    "                required: true\n",
    "                min: 0\n",
    "                max: 1000000\n",
    "\n",
    "              # 段落入力の例\n",
    "              - type: paragraph\n",
    "                variable: danraku\n",
    "                label: 段落\n",
    "                required: true\n",
    "                max_length: 48\n",
    "                options: []\n",
    "\n",
    "              # 短文入力の例\n",
    "              - type: text-input\n",
    "                variable: tanbun\n",
    "                label: 短文\n",
    "                required: true\n",
    "                max_length: 48\n",
    "                options: []    \n",
    "\n",
    "      ## start_node description:\n",
    "      start node\n",
    "         ユースケース:\n",
    "         - ワークフローの開始点として機能\n",
    "         - ユーザーからの入力を受け付け\n",
    "         - 入力された情報を変数として保存\n",
    "\n",
    "         構造:\n",
    "         - id: ユニークなID（必須）\n",
    "         - type: start（固定）\n",
    "         - variables: 入力変数の配列（必須）\n",
    "           - type: 変数の型（必須）\n",
    "           - variable: 変数名（必須）\n",
    "           - label: 表示ラベル（必須）\n",
    "           - required: 必須入力かどうか（必須）\n",
    "           - その他設定（型に応じて必要）\n",
    "\n",
    "         変数型と固有設定:\n",
    "         - file（ファイル入力）:\n",
    "           - allowed_file_types: 許可するファイルタイプ\n",
    "             - document: ドキュメントファイル\n",
    "             - image: 画像ファイル\n",
    "             - audio: 音声ファイル\n",
    "             - video: 動画ファイル\n",
    "           - allowed_file_upload_methods: アップロード方法\n",
    "             - local_file: ローカルファイル\n",
    "             - remote_url: リモートURL\n",
    "           - max_length: 最大ファイル名長\n",
    "           - required: 必須項目かどうか\n",
    "         - number（数値入力）:\n",
    "           - min: 最小値（オプション）\n",
    "           - max: 最大値（オプション）\n",
    "         - paragraph（段落テキスト）:\n",
    "           - max_length: 最大文字数（オプション）\n",
    "           - options: 選択肢（オプション）\n",
    "         - text-input（短文テキスト）:\n",
    "           - max_length: 最大文字数（オプション）\n",
    "           - options: 選択肢（オプション）              \n",
    "      \"\"\"\n",
    "    return start_node_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool\n",
    "def end_node(\n",
    "    input: Annotated[str, 'input形式']\n",
    "    ) -> str:\n",
    "    \"\"\" end node の仕様を返す\"\"\"\n",
    "    context = \"\"\"\n",
    "      ## end_node specification:\n",
    "          end_node:\n",
    "            - id: ユニークなID\n",
    "            - type: end\n",
    "            - outputs: #出力変数の定義\n",
    "              - input_data: 入力データ\n",
    "              - generated_text: 生成されたテキスト\n",
    "      ## end_node description:\n",
    "      end node\n",
    "         ユースケース:\n",
    "         - ワークフローの終了点として機能\n",
    "         - 処理結果の出力を定義\n",
    "         - 後続システムへのデータ受け渡し\n",
    "\n",
    "         構造:\n",
    "         - id: ユニークなID（必須）\n",
    "         - type: end（固定）\n",
    "         - outputs:（必須）\n",
    "           - value_selector:（必須）\n",
    "             - [ノードID]\n",
    "             - [変数名]\n",
    "           - variable: 出力変数名（必須）\n",
    "\n",
    "         特記事項:\n",
    "         - 少なくとも1つの出力変数が必要\n",
    "         - 複数の出力変数を定義可能\n",
    "    \"\"\"\n",
    "    return context\n",
    "\n",
    "@tool\n",
    "def template_node(\n",
    "    input: Annotated[str, 'input形式']\n",
    "    ) -> int:\n",
    "    \"\"\" template node の仕様を返す\"\"\"\n",
    "    context = \"\"\"\n",
    "      ## template_transform_node specification:\n",
    "          template_transform_node:\n",
    "            - id: ユニークなID\n",
    "            - type: template-transform\n",
    "            - data:\n",
    "                title: テンプレート変換\n",
    "                template: テンプレート文字列（Jinja2形式）\n",
    "                variables:\n",
    "                  - value_selector:  # 入力変数の指定\n",
    "                    - [入力ノードID]\n",
    "                    - [変数名]\n",
    "                    variable: [テンプレート内で使用する変数名]\n",
    "                outputs:\n",
    "                  output:  # 固定の出力変数名\n",
    "                    type: string  # 常にstring型\n",
    "      ## template_transform_node description:\n",
    "      Template Transformノード\n",
    "          ユースケース:\n",
    "          - テンプレート文字列への変数埋め込み\n",
    "          - 動的なメッセージ生成\n",
    "          - 条件付きテキスト生成\n",
    "          - 配列データの文字列化\n",
    "\n",
    "          構造:\n",
    "          - id: ユニークなID（必須）\n",
    "          - type: template-transform（固定）\n",
    "          - data:\n",
    "              title: ノードのタイトル（必須）\n",
    "              template: Jinja2形式のテンプレート（必須）\n",
    "              variables: 入力変数の配列（必須）\n",
    "                - value_selector: 変数の参照元\n",
    "                  - [入力ノードID]\n",
    "                  - [変数名]\n",
    "                  variable: テンプレート内で使用する変数名\n",
    "\n",
    "          テンプレート構文:\n",
    "          - 変数参照: \n",
    "            - 基本形: {{ 変数名 }}\n",
    "            - フィルター使用: {{ 変数名|upper }}\n",
    "          - 条件分岐:\n",
    "            ```\n",
    "            {% if 条件 %}\n",
    "              条件成立時の文字列\n",
    "            {% else %}\n",
    "              条件不成立時の文字列\n",
    "            {% endif %}\n",
    "            ```\n",
    "          - ループ処理:\n",
    "            ```\n",
    "            {% for item in items %}\n",
    "              {{ item }}\n",
    "            {% endfor %}\n",
    "            ```\n",
    "\n",
    "          入力変数の型:\n",
    "          - string: 文字列\n",
    "          - number: 数値\n",
    "          - object: オブジェクト\n",
    "          - array: 配列\n",
    "          - arrayNumber: 数値配列\n",
    "          - arrayString: 文字列配列\n",
    "          - arrayObject: オブジェクト配列\n",
    "\n",
    "          出力:\n",
    "          - output: 生成された文字列（string型固定）\n",
    "        \"\"\"\n",
    "    return context\n",
    "\n",
    "@tool\n",
    "def llm_node(\n",
    "    input: Annotated[str, 'input形式']\n",
    "    ) -> int:\n",
    "    \"\"\" llm node の仕様を返す\"\"\"\n",
    "    context = \"\"\"\n",
    "        nodes:\n",
    "          llm_node:\n",
    "            - id: ユニークなID\n",
    "            - type: llm\n",
    "            - model:\n",
    "              - provider: openai\n",
    "              - name: gpt-4o\n",
    "              - mode: chat\n",
    "              - completion_params:\n",
    "                - temperature: 生成時の温度設定\n",
    "            - prompt_template:\n",
    "              - id: ユニークなID(例'prompt1')\n",
    "                role: system\n",
    "                text: シングートで括ったプロンプトテキスト\n",
    "            - context:\n",
    "              - enabled: true\n",
    "              - variable_selector: 使用する変数の指定\n",
    "            - vision:\n",
    "              - enabled: false\n",
    "\n",
    "      ## llm_node description:\n",
    "      LLMノード\n",
    "         ユースケース:\n",
    "         - テキスト生成や応答の作成\n",
    "         - 入力テキストの加工や変換\n",
    "         - 質問への回答生成\n",
    "         構造:\n",
    "         - id: ユニークなID（必須）\n",
    "         - type: llm（固定）\n",
    "         - model:（必須）\n",
    "           - provider: openai（固定）\n",
    "           - name: gpt-4o（固定）\n",
    "           - mode: chat（固定）\n",
    "           - completion_params:\n",
    "             - temperature: 0.0-1.0の値（必須）\n",
    "         - prompt_template:（必須）\n",
    "           - role: system（固定）\n",
    "           - text: プロンプトテキスト（必須）\n",
    "         - context:（必須）\n",
    "           - enabled: true（固定）\n",
    "           - variable_selector: 使用する変数の指定（必須）\n",
    "         - vision:\n",
    "           - enabled: false（固定）\n",
    "         特記事項:\n",
    "         - プロンプトはシングルクォートで括る必要あり\n",
    "         - システムロールのプロンプトのみ使用可能\n",
    "         - 変数参照形式: {{#ノードID.変数名#}}\n",
    "         - contextのvariable_selectorで指定した変数は、prompt_templateのtextでも使用して下さい。\n",
    "         \n",
    "              \n",
    "    \"\"\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"\"\"\n",
    "app:\n",
    "    mode: workflow\n",
    "    name: Simple Template Workflow\n",
    "    version: 0.1.5\n",
    "\n",
    "workflow:\n",
    "    graph:\n",
    "        edges:\n",
    "        - source: 1700000000001  # StartノードID\n",
    "          target: 1700000000002  # Template-TransformノードID\n",
    "          data:\n",
    "            sourceType: start\n",
    "            targetType: template-transform\n",
    "        - source: 1700000000002  # Template-TransformノードID\n",
    "          target: 1700000000003  # EndノードID\n",
    "          data:\n",
    "            sourceType: template-transform\n",
    "            targetType: end\"\"\"\n",
    "\n",
    "\n",
    "# プロンプトの定義\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            '与えられたワークフローに従ってノードの情報を呼び出してください',\n",
    "        ),\n",
    "        ('placeholder', '{messages}'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# エージェントの作成\n",
    "agent = create_react_agent(\n",
    "    model=ChatOpenAI(model='gpt-4o-mini'),\n",
    "    tools=[start_node, end_node, template_node, llm_node],\n",
    "    state_modifier=prompt\n",
    ")\n",
    "\n",
    "# エージェントの実行\n",
    "result = agent.invoke({'messages': [message]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下は、ワークフロー内の各ノードの情報です：\n",
      "\n",
      "### Start Node Specification\n",
      "- **ID**: ユニークなID\n",
      "- **Type**: start\n",
      "- **Variables**:\n",
      "  - **File Input**\n",
      "    - Type: file\n",
      "    - Variable: input_document\n",
      "    - Label: ドキュメント\n",
      "    - Required: true\n",
      "    - Max Length: 48\n",
      "    - Allowed File Types: document\n",
      "    - Allowed File Upload Methods: local_file, remote_url\n",
      "  - **Number Input**\n",
      "    - Type: number\n",
      "    - Variable: input_number\n",
      "    - Label: 数値\n",
      "    - Required: true\n",
      "    - Min: 0\n",
      "    - Max: 1000000\n",
      "  - **Paragraph Input**\n",
      "    - Type: paragraph\n",
      "    - Variable: danraku\n",
      "    - Label: 段落\n",
      "    - Required: true\n",
      "    - Max Length: 48\n",
      "    - Options: []\n",
      "  - **Text Input**\n",
      "    - Type: text-input\n",
      "    - Variable: tanbun\n",
      "    - Label: 短文\n",
      "    - Required: true\n",
      "    - Max Length: 48\n",
      "    - Options: []\n",
      "\n",
      "### Template Transform Node Specification\n",
      "- **ID**: ユニークなID\n",
      "- **Type**: template-transform\n",
      "- **Data**:\n",
      "  - **Title**: テンプレート変更\n",
      "  - **Template**: テンプレート文字列（Jinja2形式）\n",
      "  - **Variables**:\n",
      "    - Value Selector:\n",
      "      - [入力ノードID]\n",
      "      - [変数名]\n",
      "      - Variable: [テンプレート内で使用する変数名]\n",
      "  - **Outputs**:\n",
      "    - Output:\n",
      "      - Type: string\n",
      "\n",
      "### End Node Specification\n",
      "- **ID**: ユニークなID\n",
      "- **Type**: end\n",
      "- **Outputs**:\n",
      "  - Input Data: 入力データ\n",
      "  - Generated Text: 生成されたテキスト\n",
      "\n",
      "この情報は、各ノードが持つべき属性や機能の概要を示しています。\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_prompt =\"\"\"\n",
    "    output_format: |\n",
    "      生成されるYAMLファイルは以下の形式に従ってください：\n",
    "      ```yaml\n",
    "      app:\n",
    "        mode: workflow\n",
    "        name: [ワークフロー名]\n",
    "        version: 0.1.5\n",
    "\n",
    "      workflow:\n",
    "        graph:\n",
    "          edges:\n",
    "            # IF/ELSE分岐のエッジ例\n",
    "            - source: [IF/ELSEノードID]\n",
    "              target: [ターゲットノードID]\n",
    "              data:\n",
    "                sourceType: if-else\n",
    "                targetType: [ターゲットノードタイプ]\n",
    "              sourceHandle: 'true'  # IF条件成立時\n",
    "            - source: [IF/ELSEノードID]\n",
    "              target: [別のターゲットノードID]\n",
    "              data:\n",
    "                sourceType: if-else\n",
    "                targetType: [ターゲットノードタイプ]\n",
    "              sourceHandle: 'false'  # ELSE条件時\n",
    "\n",
    "          nodes:\n",
    "            - id: [開始ノードID]\n",
    "              data:\n",
    "                type: start\n",
    "                title: 開始\n",
    "                variables:\n",
    "                  # ファイル入力の例\n",
    "                  - type: file\n",
    "                    variable: input_document\n",
    "                    label: ドキュメント\n",
    "                    required: true\n",
    "                    max_length: 48\n",
    "                    allowed_file_types:\n",
    "                      - document\n",
    "                    allowed_file_upload_methods:\n",
    "                      - local_file\n",
    "                      - remote_url\n",
    "\n",
    "                  # その他の入力タイプ\n",
    "                  - type: text-input\n",
    "                    variable: [変数名]\n",
    "                    type: string/number\n",
    "                    label: [入力フィールドのラベル]\n",
    "                    required: true\n",
    "                    max_length: [最大文字数]\n",
    "\n",
    "            - id: [LLMノードID]\n",
    "              data:\n",
    "                type: llm\n",
    "                title: LLM\n",
    "                model:\n",
    "                  provider: openai\n",
    "                  name: gpt-4o\n",
    "                  mode: chat\n",
    "                  completion_params:\n",
    "                    temperature: 0.7\n",
    "                prompt_template:\n",
    "                  - id: [プロンプトID]\n",
    "                    role: system\n",
    "                    text: '[プロンプトテキスト]'\n",
    "                context:\n",
    "                  enabled: true\n",
    "                  variable_selector:\n",
    "                    - [開始ノードID]\n",
    "                    - [変数名]\n",
    "                vision:\n",
    "                  enabled: false\n",
    "            - id: [終了ノードID]\n",
    "              data:\n",
    "                type: end\n",
    "                title: 終了\n",
    "                outputs:\n",
    "                  - value_selector:\n",
    "                      - [開始ノードID]\n",
    "                      - [変数名]\n",
    "                    variable: inputData\n",
    "                  - value_selector:\n",
    "                      - [LLMノードID]\n",
    "                      - text\n",
    "                    variable: generatedText\n",
    "            - id: [テンプレートノードID]\n",
    "              data:\n",
    "                type: template-transform\n",
    "                title: テンプレート変換\n",
    "                template: |\n",
    "                  こんにちは、{{ user_name }}さん！\n",
    "                  あなたの得点は{{ score }}点です。\n",
    "                  {% if score >= 80 %}\n",
    "                  合格です！おめでとうございます。\n",
    "                  {% else %}\n",
    "                  残念ながら不合格です。\n",
    "                  {% endif %}\n",
    "                variables:\n",
    "                  - value_selector:\n",
    "                      - [入力ノードID]\n",
    "                      - user_name\n",
    "                    variable: user_name\n",
    "                  - value_selector:\n",
    "                      - [入力ノードID]\n",
    "                      - score\n",
    "                    variable: score\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プロンプトの定義\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            '与えられたワークフローに従ってノードの情報を呼び出してください',\n",
    "        ),\n",
    "        ('placeholder', '{messages}'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# エージェントの作成\n",
    "agent = create_react_agent(\n",
    "    model=ChatOpenAI(model='gpt-4o-mini'),\n",
    "    tools=[start_node, end_node, template_node, llm_node],\n",
    "    state_modifier=prompt\n",
    ")\n",
    "\n",
    "# エージェントの実行\n",
    "result = agent.invoke({'messages': [message]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '3 + 4の計算結果は？', 'output': '3 + 4の計算結果は7です。'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# toolの定義\n",
    "@tool\n",
    "def add(\n",
    "    a: Annotated[int, '一つ目の値'],\n",
    "    b: Annotated[int, '二つ目の値'],\n",
    ") -> int:\n",
    "    \"\"\"2つの値を足し算して返す\"\"\"\n",
    "    return a + b\n",
    "\n",
    "# プロンプトの定義\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            'system',\n",
    "            '与えられたinputに従って計算処理を呼び出してください',\n",
    "        ),\n",
    "        ('human', '{input}'),\n",
    "        # Placeholders fill up a **list** of messages\n",
    "        ('placeholder', '{agent_scratchpad}'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# エージェントを作成\n",
    "agent = create_tool_calling_agent(ChatOpenAI(model='gpt-3.5-turbo'), [add], prompt)\n",
    "\n",
    "# エージェントを実行\n",
    "agent_executor = AgentExecutor(agent=agent, tools=[add])\n",
    "result = agent_executor.invoke({'input': '3 + 4の計算結果は？'})\n",
    "print(result)\n",
    "# => {'input': '3 + 4の計算結果は？', 'output': '3 + 4の計算結果は、7です。'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m initialize_agent, Tool\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrkl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m prompt\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents.mrkl import prompt\n",
    "\n",
    "# Toolデコレーターを関数に付ける\n",
    "@tool\n",
    "def weather_function(location):\n",
    "    match location:\n",
    "      case \"東京\" | \"Tokyo\":\n",
    "        weather = \"晴れ\"\n",
    "      case \"大阪\" | \"Osaka\":\n",
    "        weather = \"曇り\"\n",
    "      case \"北海道\" | \"Hokkaido\":\n",
    "        weather = \"雪\"\n",
    "      case _ :\n",
    "        weather = \"不明\"\n",
    "\n",
    "    weather_answer = [\n",
    "        {\"天気\": weather}\n",
    "    ]\n",
    "\n",
    "    return json.dumps(weather_answer)\n",
    "\n",
    "\n",
    "def lang_chain_agent(text):\n",
    "    llm = OpenAI(model_name='gpt-4o-mini')\n",
    "    # toolsに利用したいToolを格納する。LangChainで用意されたToolを利用することも出来る。\n",
    "    # 代表的なTool一覧：https://book.st-hakky.com/docs/agents-of-langchain/\n",
    "    tools = [\n",
    "        Tool(\n",
    "            name = \"Weather\",\n",
    "            func=weather_function,\n",
    "            description=\"天気を知りたい場所を入力。例: 東京\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # エージェントの準備\n",
    "    agent = initialize_agent(\n",
    "        tools,\n",
    "        llm,\n",
    "        agent=\"zero-shot-react-description\",\n",
    "        # AIの回答を日本語にするために必要\n",
    "        agent_kwargs=dict(suffix='Answer should be in Japanese.' + prompt.SUFFIX), \n",
    "        # 以下2行を有効にしておくことで、agentの動きを確認しやすい\n",
    "        # AIの回答のみ欲しい場合はFalseにする\n",
    "        verbose=True,\n",
    "        return_intermediate_steps=True)\n",
    "\n",
    "    response = agent({\"input\": text})\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
